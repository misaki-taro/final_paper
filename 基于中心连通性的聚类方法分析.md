# 基于中心连通性的聚类方法分析

## 1. 绪论

​		聚类分析起源于分类学，在古老的分类学中，人们主要依靠经验和专业知识来实现分类，很少利用数学工具进行定量的分类,致使许多分类带有主观性和任意性，不能很好地揭示客观事物内在的本质区别与联系，特别是对于多个特征、多指标的分类问题更难以实现客观的分类。随着人类科学技术的发展，对分类的要求越来越高，于是人们逐渐地把数学工具引用到了分类学中，形成了数值分类学，之后又将多元分析的技术引入到数值分类学形成了聚类分析。

​		聚类分析在许多领域中都得到了广泛的应用，取得了许多成果。

### 1.1 聚类分析的基本思想

​		聚类分析认为，所研究的样本之间存在不同程度的相似性。根据多个样本的多个特征，找出能够表示样本之间的相似性的度量，并且根据这种度量采用某些聚类方法，将所有的样品分配到不同的种类当中去，使同一种类中的样本具有较大的相似性，不同类中的样本相似性小。我们将这种分类方法称为聚类分析。

### 1.2 聚类分析的内容

​		聚类中心和聚类数目的确定是聚类分析的关键。许多聚类方法已经被广泛探索过。常见的聚类方法有K-Means聚类、均值漂移聚类、基于密度的聚类、层次聚类等聚类方法、基于图论的聚类等聚类方法。本文主要介绍基于中心连通性的聚类方法。基于中心连通性的聚类方法是基于图论的方法。

​		每种聚类分析方法都涉及事物之间的相似性。聚类分析方法的本质就是寻找一个客观能反应样本之间相关联系的统计量，然后根据这种统计量把样本分成若干类，常用的统计量有距离和相似系数。

#### 1.2.1相似性度量——距离

用距离来衡量样本之间的相似程度。假设$d(x_i,x_j)$是样本$x_i$和样本$x_j$的距离。常用距离:

欧式距离: $d(x_i,x_j)=[\sum_{k=1}^{p}(x_{ik}-x_{jk})^2]^\frac{1}{2}$;

绝对距离: $d(x_i,x_j)=\sum_{k=1}^{p}\left | x_{ik}-x_{jk} \right |$;

Minkowski距离: $d(x_i,x_j)=[\sum_{k=1}^{p}(x_{ik}-x_{jk})^m]^\frac{1}{m}$



#### 1.2.2相似性度量——相关系数

对n个样本进行聚类的时候，用相似系数来衡量变量之间相关联程度。用$c_{\alpha \beta }$表示样本$x_{\alpha}$和样本$x_{\beta}$之间的相似系数，应当满足以下条件：

(1)	$\left | c_{\alpha \beta } \right |\leqslant 1$且$c_{\alpha \alpha }= 1$

(2)	$c_{\alpha \beta }=_{\beta \alpha }$

$\left | c_{\alpha \beta } \right |$越接近1，说明$x_{\alpha}$和$x_{\beta}$越相关，相似系数中最常用的是相关系数和夹角余弦。在基于图的聚类中，我们通常使用高斯核函数。鉴于本文研究内容，下面介绍基于中心连通性的聚类方法相关内容。

## 2.基于中心连通性的聚类方法及其研究

### 2.1基于中心连通性的聚类方法

### 2.2可行性（iris，ARI？）

## 3.基于中心连通性聚类方法的应用

### 3.1高光谱以及band selection

3.2将CCE应用于HSI的BS

3.3Edge Detect

3.4CCE+Edge Detect+BS